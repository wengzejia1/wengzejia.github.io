<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
    <title>Zejia Weng - Fudan University</title>
    <meta name="description" content="Artificial General Intelligence">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="https://fonts.googleapis.com/css?family=Alegreya" rel="stylesheet">
    <!--<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400|Oswald:400,700' rel='stylesheet' type='text/css'>-->
    <link href="style.css" rel=stylesheet>
    <script>
        function showbib(tag) {
            var x = document.getElementById(tag);
            if (x.style.display == "block")
                x.style.display = "none";
            else x.style.display = "block";
        }
    </script>
</head>

<body>
    <div id=main>

    <!-- <div style="padding-top: 10px">
        <div style="float:right">
            <a class=link href="">Home</a>
                    &nbsp;&nbsp;&nbsp;
                    <a class=link href="">Publications</a>
                    <br><br>
        </div>
    </div> -->

        <div style="padding-top: 10px">

            <div style="float:left">
                <div class=name>Zuxuan Wu</div>
                <p> 4-th year Ph.D<br>School of Computer Science, Fudan University
                <p><a class=link href="mailto:zjweng20@fudan.edu.cn">Email</a>
                    <!--<a class="cv" href="resume-angli.pdf">Resume</a> -->&nbsp;&nbsp;&nbsp;
                    <a class=link href="https://scholar.google.com/citations?user=qMT0sqAAAAAJ&hl=zh-CN">Google Scholar</a>
                    <br><br>
            </div>
            <div style="clear:both;"></div>
        </div>
        <div class=section>
            <h3>Biography</h3>
            <p> I am a 4-th year Ph.D Candidate in School of Computer Science at Fudan University supervised by <a href="https://zxwu.azurewebsites.net/">Prof. Zuxuan Wu</a> and <a href="https://scholar.google.com/citations?user=f3_FP8AAAAAJ&hl=en">Prof. Yu-Gang Jiang</a>. I am a member of the <a href="https://fvl.fudan.edu.cn/">Fudan Vision and Learning Laboratory</a>. Before this, I recieved my BS degree in Computer Science from the Fudan University with <a href="https://scholar.google.com/citations?user=f3_FP8AAAAAJ&hl=en">Prof. Yu-Gang Jiang</a> in 2020. My research interests are in computer vision and deep learning. My current research particularly focuses on large-scale video understanding and multimodal learning.

            <p>I'm set to graduate in 2025 and actively exploring job opporunities in both industry and academia. If you are interested in working with me, please feel free to email me.


            <div class=section>
                <h3>Publication</h3>

                <ul class=paper>
                   
                    <li><a href="https://arxiv.org/abs/2311.14671">SEGIC: Unleashing the Emergent Correspondence for In-Context Segmentation.</a><br>European Conference on Computer Vision (<b>ECCV</b>), Milano, Italy, Sept., 2024. <br> <span class=authors>Lingchen Meng, Shiyi Lan, Hengduo Li, Jose M. Alvarez, <b>Zuxuan Wu</b>, Yu-Gang Jiang
                    </span> </li>

                    <li><a href="https://arxiv.org/abs/2303.07223">PromptFusion: Decoupling Stability and Plasticity for Continual Learning.</a><br>European Conference on Computer Vision (<b>ECCV</b>), Milano, Italy, Sept., 2024. <br> <span class=authors>Haoran Chen, <b>Zuxuan Wu</b>, Xintong Han, Menglin Jia, Yu-Gang Jiang
                    </span> </li>

                    <li><a href="https://arxiv.org/abs/2311.17338">MagDiff: Multi-Alignment Diffusion for High-Fidelity Video Generation and Editing.</a><br>European Conference on Computer Vision (<b>ECCV</b>), Milano, Italy, Sept., 2024. <br> <span class=authors>Haoyu Zhao, Tianyi Lu, Jiaxi Gu, Xing Zhang, Qingping Zheng, <b>Zuxuan Wu</b>, Hang Xu, Yu-Gang Jiang
                    </span> </li>


                    <li><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_OmniViD_A_Generative_Framework_for_Universal_Video_Understanding_CVPR_2024_paper.pdf">OmniViD: A Generative Framework for Universal Video Understanding.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Seattle, USA, June, 2024. <br> <span class=authors>Junke Wang, Dongdong Chen, Chong Luo, Bo He, Lu Yuan, <b>Zuxuan Wu</b>, Yu-Gang Jiang
                    </span> </li>

                    <li><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Tu_MotionEditor_Editing_Video_Motion_via_Content-Aware_Diffusion_CVPR_2024_paper.pdf">MotionEditor: Editing Video Motion via Content-Aware Diffusion.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Seattle, USA, June, 2024.<a class=link href="https://github.com/Francis-Rings/MotionEditor">code</a> <br> <span class=authors>Shuyuan Tu, Qi Dai, Zhi-Qi Cheng, Han Hu, Xintong Han, <b>Zuxuan Wu</b>, Yu-Gang Jiang
                    </span> </li>

                    <li><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xing_SimDA_Simple_Diffusion_Adapter_for_Efficient_Video_Generation_CVPR_2024_paper.pdf">SimDA: Simple Diffusion Adapter for Efficient Video Generation.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Seattle, USA, June, 2024. <br> <span class=authors>Zhen Xing, Qi Dai, Han Hu, <b>Zuxuan Wu</b>, Yu-Gang Jiang
                    </span> </li>

                   
                    <li><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Luo_Learning_to_Rank_Patches_for_Unbiased_Image_Redundancy_Reduction_CVPR_2024_paper.pdf">Learning to Rank Patches for Unbiased Image Redundancy Reduction.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Seattle, USA, June, 2024. <br> <span class=authors>Yang Luo, Zhineng Chen, Peng Zhou, <b>Zuxuan Wu</b>, Xieping Gao, Yu-Gang Jiang
                    </span> </li>
     


                    <li><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Peng_Synthesize_Diagnose_and_Optimize_Towards_Fine-Grained_Vision-Language_Understanding_CVPR_2024_paper.pdf">Synthesize Diagnose and Optimize: Towards Fine-Grained Vision-Language Understanding.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Seattle, USA, June, 2024. <a class=link href="https://github.com/wjpoom/SPEC">code</a><br> <span class=authors>Wujian Peng, Sicheng Xie, Zuyao You, Shiyi Lan, <b>Zuxuan Wu</b>
                    </span> </li>

                    <li><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Li_BEVNeXt_Reviving_Dense_BEV_Frameworks_for_3D_Object_Detection_CVPR_2024_paper.pdf">           BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Seattle, USA, June, 2024. <br> <span class=authors>Zhenxin Li, Shiyi Lan, Jose M. Alvarez, <b>Zuxuan Wu</b>  
                    </span> </li>

                    
                    <li><a href="https://arxiv.org/abs/2209.15210">Multi-Prompt Alignment for Multi-Source Unsupervised Domain Adaptation.</a><br>Advances in Neural Information Processing Systems (<b>NeurIPS</b>), New Orleans, USA, Dec., 2023. <br> <span class=authors>Haoran Chen, Xintong Han, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
         

                    <li><a href="https://arxiv.org/abs/2310.12152">Learning from Rich Semantics and Coarse Locations for Long-tailed Object Detection.</a><br>Advances in Neural Information Processing Systems (<b>NeurIPS</b>), New Orleans, USA, Dec., 2023. <a class=link href="">code</a> <br> <span class=authors>Lingchen Meng, Xiyang Dai, Jianwei Yang, Dongdong Chen, Yinpeng Chen, Mengchen Liu, Yi-Ling Chen, <b>Zuxuan Wu</b>, Lu Yuan, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2304.10465">Implicit Temporal Modeling with Learnable Alignment for Video Recognition.</a><br>International Conference on Computer Vision (<b>ICCV</b>), Paris, France, Oct., 2023 (Oral) <a class=link href="https://github.com/Francis-Rings/ILA">code</a> <br> <span class=authors>Shuyuan Tu, Qi Dai, <b>Zuxuan Wu</b>, Zhi-Qi Cheng, Han Hu, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2302.00624">Open-VCLIP: Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization.</a><br>International Conference on Machine Learning (<b>ICML</b>), Hawaii, USA, July, 2023 <br> <span class=authors>Zejia Weng, Xitong Yang, Ang Li, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2212.00776">ResFormer: Scaling ViTs with Multi-Resolution Training.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Rui Tian, <b>Zuxuan Wu</b>, Qi Dai, Han Hu, Yu Qiao, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2211.13222">SVFormer: Semi-Supervised Video Transformer for Action Recognition.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Zhen Xing, Qi Dai, Han Hu, Jingjing Chen, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2206.03484">Detection Hub: Unifying Object Detection Datasets via Query Adaptation on Language Embedding.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Lingchen Meng, Xiyang Dai, Yinpeng Chen, Pengchuan Zhang, Dongdong Chen, Mengchen Liu, Jianfeng Wang, <b>Zuxuan Wu</b>, Lu Yuan, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2212.06826">Look Before You Match: Instance Understanding Matters in Video Object Segmentation.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Junke Wang, Dongdong Chen, <b>Zuxuan Wu</b>, Chong Luo, Chuanxin Tang, Xiyang Dai, Yucheng Zhao, Yujia Xie, Lu Yuan, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2212.04500">Masked Video Distillation: Rethinking Masked Feature Modeling for Self-supervised Video Representation Learning.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Rui Wang, Dongdong Chen, <b>Zuxuan Wu</b>, Yinpeng Chen, Xiyang Dai, Mengchen Liu, Lu Yuan, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2212.02031">Prototypical Residual Networks for Anomaly Detection and Localization.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Hui Zhang, <b>Zuxuan Wu</b>, Zheng Wang, Zhineng Chen, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2209.03716">Enhancing the Self-Universality for Transferable Targeted Attacks.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Zhipeng Wei, Jingjing Chen, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2301.03992">Vision Transformers are Good Mask Auto-Labelers.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Shiyi Lan, Xitong Yang, Zhiding Yu, <b>Zuxuan Wu</b>, Jose M. Alvarez, Anima Anandkumar</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2303.14124">Towards Scalable Neural Representation for Diverse Videos.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June, 2023 <br> <span class=authors>Bo He, Xitong Yang, Hanyu Wang, <b>Zuxuan Wu</b>, Hao Chen, Shuaiyi Huang, Yixuan Ren, Ser-Nam Lim, Abhinav Shrivastava</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2212.14284">Resolving Task Confusion in Dynamic Expansion Architectures for Class Incremental Learning.</a><br>The AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Washington DC, USA, Feb., 2023 <br> <span class=authors>Bingchen Huang, Zhineng Chen, Peng Zhou, Jiayin Chen, <b>Zuxuan Wu</b></span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2209.07526">OmniVL: One Foundation Model for Image-Language and Video-Language Tasks.</a><br>Advances in Neural Information Processing Systems (<b>NeurIPS</b>), New Orleans, USA, Dec., 2022. <br> <span class=authors>Junke Wang, Dongdong Chen, <b>Zuxuan Wu</b>, Chong Luo, Luowei Zhou, Yucheng Zhao, Yujia Xie, Ce Liu, Yu-Gang Jiang, Lu Yuan</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2111.11067">Semi-Supervised Vision Transformers.</a><br>European Conference on Computer Vision (<b>ECCV</b>), Tel Aviv, October, 2022. <a class=link href="https://github.com/wengzejia1/Semiformer">code</a> <br> <span class=authors>Zejia Weng, Xitong Yang, Ang Li, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2111.11591">Efficient Video Transformers with Spatial-Temporal Token Selection.</a><br>European Conference on Computer Vision (<b>ECCV</b>), Tel Aviv, October, 2022. <a class=link href="https://github.com/wangjk666/STTS">code</a> <br> <span class=authors>Junke Wang, Xitong Yang, Hengduo Li, Li Liu, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="">Semi-Supervised Single-View 3D Reconstruction via Prototype Shape Priors.</a><br>European Conference on Computer Vision (<b>ECCV</b>), Tel Aviv, October, 2022. <a class=link href="">code</a> <br> <span class=authors>Zhen Xing, Hengduo Li, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2112.01529">BEVT: BERT Pretraining of Video Transformers.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), New Orleans, USA, June, 2022 <a class=link href="https://github.com/xyzforever/BEVT/">code</a> <br> <span class=authors>Rui Wang, Dongdong Chen, <b>Zuxuan Wu</b>, Yinpeng Chen, Xiyang Dai, Mengchen Liu, Yu-Gang Jiang, Luowei Zhou, Lu Yuan</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2112.05379">Cross-Modal Transferable Adversarial Attacks from Images to Videos.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), New Orleans, USA, June, 2022 <br> <span class=authors>Zhipeng Wei, Jingjing Chen, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2111.15668">AdaViT: Adaptive Vision Transformers for Efficient Image Recognition.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), New Orleans, USA, June, 2022 <br> <span class=authors>Lingchen Meng, Hengduo Li, Bor-Chun Chen, Shiyi Lan, <b>Zuxuan Wu</b>, Yu-Gang Jiang, Ser-Nam Lim</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2203.14681">ObjectFormer for Image Manipulation Detection and Localization.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), New Orleans, USA, June, 2022 <br> <span class=authors>Junke Wang, <b>Zuxuan Wu</b>, Jingjing Chen, Xintong Han, Abhinav Shrivastava, Ser-Nam Lim, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/pdf/2010.09891">Flag: Adversarial data augmentation for graph neural networks.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), New Orleans, USA, June, 2022 <br> <span class=authors>Kezhi Kong, Guohao Li, Mucong Ding, <b>Zuxuan Wu</b>, Chen Zhu, Bernard Ghanem, Gavin Taylor, Tom Goldstein</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2110.09075">Boosting the Transferability of Video Adversarial Examples via Temporal Translation.</a><br>The AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Virtual, Feb., 2022 <br> <span class=authors>Zhipeng Wei, Jingjing Chen, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>

                    <li><a href="https://arxiv.org/abs/2110.15629">Attacking Video Recognition Models with Bullet-Screen Comments.</a><br>The AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Virtual, Feb., 2022 <br> <span class=authors>Kaichen, Zhipeng Wei, Jingjing Chen, <b>Zuxuan Wu</b>, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2109.04176">Towards Transferable Adversarial Attacks on Vision Transformers.</a><br>The AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Virtual, Feb., 2022 <br> <span class=authors>Zhipeng Wei, Jingjing Chen, Micah Goldblum, <b>Zuxuan Wu</b>, Tom Goldstein, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2106.00168">Rethinking Pseudo Labels for Semi-Supervised Object Detection.</a><br>The AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Virtual, Feb., 2022 <br> <span class=authors>Hengduo Li, <b>Zuxuan Wu</b>, Abhinav Shrivastava, Larry Davis</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2009.08965">Encoding Robustness to Image Style via Adversarial Feature Perturbations.</a><br>Advances in Neural Information Processing Systems (<b>NeurIPS</b>), Virtual, Dec., 2021. <br> <span class=authors>Manli Shu, <b>Zuxuan Wu</b>, Micah Goldblum, Tom Goldstein</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2101.11080">Deep Video Inpainting Detection.</a><br>British Machine Vision Conference (<b>BMVC</b>), Virtual, Oct., 2021 <br> <span class=authors>Peng Zhou, Ning Yu, <b>Zuxuan Wu</b>, Larry Davis, Abhinav Shrivastava, Ser-Nam Lim</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2012.08510">GTA: Global Temporal Attention for Video Action Understanding.</a><br>British Machine Vision Conference (<b>BMVC</b>), Virtual, Oct., 2021 <br> <span class=authors>Bo He, Xitong Yang, <b>Zuxuan Wu</b>, Hao Chen, Ser-Nam Lim, Abhinav Shrivastava</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2105.02668">VideoLT: Large-scale Long-tailed Video Recognition.</a><br>International Conference on Computer Vision (<b>ICCV</b>), Virtual, Oct., 2021 <br> <span class=authors>Xing Zhang, <b>Zuxuan Wu</b>, Zejia Weng, Huazhu Fu, Jingjing Chen, Yu-Gang Jiang, Larry Davis</span> </li>
                    
                    <li><a href="https://arxiv.org/pdf/2104.07767">Exploring Visual Engagement Signals for Representation Learning.</a><br>International Conference on Computer Vision (<b>ICCV</b>), Virtual, Oct., 2021 <br> <span class=authors>Menglin Jia, <b>Zuxuan Wu</b>, Austin Reiter, Claire Cardie, Serge Belongie, Ser-Nam Lim</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2012.14950">2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Virtual, June, 2021 <br> <span class=authors>Hengduo Li, <b>Zuxuan Wu</b>, Abhinav Shrivastava, Larry S. Davis</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/2011.05558">Intentonomy: a Dataset and Study towards Human Intent Understanding.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Virtual, June, 2021 (Oral) <a class=link href="">code</a> <br> <span class=authors>Menglin Jia, <b>Zuxuan Wu</b>, Austin Reiter, Claire Cardie, Serge Belongie, Ser-Nam Lim</span> </li>
                    
                    <li><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Efficient_Object_Embedding_for_Spliced_Image_Retrieval_CVPR_2021_paper.pdf">Efficient Object Embedding for Manipulated Image Retrieval.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Virtual, June, 2021 <br> <span class=authors>Bor-Chun Chen, <b>Zuxuan Wu</b>, Larry S. Davis, Ser-Nam Lim</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/1910.14667">Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors.</a><br>European Conference on Computer Vision (<b>ECCV</b>), Virtual, August, 2020. <a class=link href="https://obj.umiacs.umd.edu/cloak-code/adversarial_cloak.zip">code</a> <br> <span class=authors><b>Zuxuan Wu</b>, Ser-Nam Lim, Larry S. Davis, Tom Goldstein</span> </li>
                    
                    <li><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Learning_From_Noisy_Anchors_for_One-Stage_Object_Detection_CVPR_2020_paper.pdf">Learning from Noisy Anchors for One-stage Object Detection.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Virtual, June, 2020 <br> <span class=authors>Hengduo Li, <b>Zuxuan Wu</b>, Chen Zhu, Caiming Xiong, Richard Socher, Larry S. Davis</span> </li>
                    
                    <li><a href="https://papers.nips.cc/paper/8993-liteeval-a-coarse-to-fine-framework-for-resource-efficient-video-recognition.pdf">LiteEval: A Coarse-to-Fine Framework for Resource Efficient Video Recognition.</a><br>Advances in Neural Information Processing Systems (<b>NeurIPS</b>), Vancouver, Canada, Dec., 2019. <a class=link href="https://github.com/zxwu/lite_eval">code</a> <br> <span class=authors><b>Zuxuan Wu</b>, Caiming Xiong, Yu-Gang Jiang, Larry S. Davis</span> </li>
                    
                    <li><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Han_FiNet_Compatible_and_Diverse_Fashion_Image_Inpainting_ICCV_2019_paper.pdf">FiNet: Compatible and Diverse Fashion Image Inpainting.</a><br>International Conference on Computer Vision (<b>ICCV</b>), Seoul, Korea, Oct., 2019. (Oral) <br> <span class=authors>Xintong Han, <b>Zuxuan Wu</b>, Weilin Huang, Matthew R. Scott, Larry S. Davis</span> </li>
                    
                    <li><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_ACE_Adapting_to_Changing_Environments_for_Semantic_Segmentation_ICCV_2019_paper.pdf">ACE: Adapting to Changing Environments for Semantic Segmentation.</a><br>International Conference on Computer Vision (<b>ICCV</b>), Seoul, Korea, Oct., 2019 <br> <span class=authors><b>Zuxuan Wu</b>, Xin Wang, Joseph E. Gonzalez, Tom Goldstein, Larry S. Davis</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/1811.12432">AdaFrame: Adaptive Frame Selection for Fast Video Recognition.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Long Beach, USA, June, 2019 <br> <span class=authors><b>Zuxuan Wu</b>, Caiming Xiong, Chih-Yao Ma, Richard Socher, Larry S Davis</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/1903.01602">The Regretful Agent: Heuristic-Aided Navigation through Progress Estimation.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Long Beach, USA, June, 2019 <br> <span class=authors>Chih-Yao Ma, <b>Zuxuan Wu</b>, Ghassan AlRegib, Caiming Xiong, Zsolt Kira</span> </li>
                    
                    <li><a href="http://www.yugangjiang.info/publication/TOMM19-RW.pdf">Visual Content Recognition by Exploiting Semantic Feature Map with Attention and Multi-task Learning.</a><br>ACM Trans. Multimedia Comput. Commun (<b>ACM TOMM</b>), vol. 15, issue 1, pp. 6:1-6:22, 2019. <br> <span class=authors>Rui-Wei Zhao, Qi Zhang, <b>Zuxuan Wu</b>, Jianguo Li, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/1901.03035">Self-Monitoring Navigation Agent via Auxiliary Progress Estimation.</a><br>International Conference on Learning Representations (<b>ICLR</b>), New Orleans, USA, May, 2019 <br> <span class=authors>Chih-Yao Ma, Jiasen Lu, <b>Zuxuan Wu</b>, Ghassan AlRegib, Zsolt Kira, Richard Socher, Caiming Xiong</span> </li>
                    
                    <li><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Zuxuan_Wu_DCAN_Dual_Channel-wise_ECCV_2018_paper.pdf">DCAN: Dual Channel-wise Alignment Networks for Unsupervised Scene Adaptation.</a><br>European Conference on Computer Vision (<b>ECCV</b>), Munich, Germany, September, 2018. <a class=link href="dcan.zip">code</a> <br> <span class=authors><b>Zuxuan Wu</b>, Xintong Han, Yen-Liang Lin, Mustafa Gkhan Uzunbas, Tom Goldstein, Ser Nam Lim, Larry S. Davis</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/1711.08393">BlockDrop: Dynamic Inference Paths in Residual Networks.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Salt Lake City, USA, June, 2018. (Spotlight) <a class=link href="https://github.com/Tushar-N/blockdrop">code</a> <br> <span class=authors><b>Zuxuan Wu</b>*, Tushar Nagarajan*, Abhishek Kumar, Steven Rennie, Larry S. Davis, Kristen Grauman, Rogerio Feris (* denotes equal contribution)</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/1711.08447">VITON: An Image-based Virtual Try-on Network.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Salt Lake City, USA, June, 2018. (Spotlight) <a class=link href="https://github.com/xthan/viton/">code</a> <br> <span class=authors>Xintong Han, <b>Zuxuan Wu</b>, Zhe Wu, Ruichi Yu, Larry S. Davis</span> </li>
                    
                    <li><a href="https://arxiv.org/pdf/1502.07209.pdf">Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks.</a><br>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol. 40, Issue 2, pp. 352-364, 2018. <br> <span class=authors>Yu-Gang Jiang, <b>Zuxuan Wu</b>, Jun Wang, Xiangyang Xue, Shih-Fu Chang</span> <br><font color="red"> <a href="http://bigvid.fudan.edu.cn/FCVID/">Fudan-Columbia Video Dataset (FCVID)</a>, one of the largest public Web video datasets with manual annotations.</font> </li>
                    
                    <li><a href="https://arxiv.org/pdf/1609.06782.pdf">Deep Learning for Video Classification and Video Captioning.</a><br>In Frontiers of Multimedia Research, Shih-Fu Chang (Ed.), ACM Morgan & Claypool, New York, NY, USA, pp. 3-29, 2018 <br> <span class=authors><b>Zuxuan Wu</b>, Ting Yao, Yanwei Fu, Yu-Gang Jiang</span> <br><font color="red">Surveying 100+ recent literatures on video classification and captioning with deep learning.</font> </li>
                    
                    <li><a href="https://arxiv.org/abs/1704.02998">Weakly-Supervised Spatial Context Networks.</a><br>arXiv preprint arXiv:1704.02998 <br> <span class=authors><b>Zuxuan Wu</b>, Larry S. Davis, Leonid Sigal</span> </li>
                    
                    <li><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Han_Automatic_Spatially-Aware_Fashion_ICCV_2017_paper.pdf">Automatic Spatially-aware Fashion Concept Discovery.</a><br>International Conference on Computer Vision (<b>ICCV</b>), Venice, Italy, Oct., 2017 <br> <span class=authors>Xintong Han, <b>Zuxuan Wu</b>, Phoenix Huang, Xiao Zhang, Menglong Zhu, Yuan Li, Yang Zhao, Larry S. Davis</span> </li>
                    
                    <li><a href="https://arxiv.org/abs/1707.05691">Learning Fashion Compatibility with Bidirectional LSTMs.</a><br>ACM Multimedia (<b>ACM MM</b>), Mountain View, USA, Oct., 2017 <br> <span class=authors>Xintong Han, <b>Zuxuan Wu</b>, Yu-Gang Jiang, Larry S. Davis</span> </li>
                    
                    <li><a href="http://www.yugangjiang.info/publication/17MM-RW.pdf">Learning Semantic Feature Map for Visual Content Recognition.</a><br>ACM Multimedia (<b>ACM MM</b>), Mountain View, USA, Oct., 2017 <br> <span class=authors>Rui-Wei Zhao, <b>Zuxuan Wu</b>, Jianguo Li, Yu-Gang Jiang</span> </li>
                    
                    <li><a href="16CVPR-OSF.pdf">Harnessing Object and Scene Semantics for Large-Scale Video Understanding.</a><br>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Las Vegas, USA, June, 2016. (Spotlight) <br> <span class=authors><b>Zuxuan Wu</b>, Yanwei Fu, Yu-Gang Jiang, Leonid Sigal</span> <br><font color="red">Featured in <a href="http://tech.firstpost.com/news-analysis/deep-learning-enables-software-to-recognise-unseen-events-in-youtube-videos-322400.html">Tech2</a>, <a href="http://www.cacm.acm.org/news/204186-object-and-scene-recognition-software-work-together-to-understand-video-content/fulltext">ACM Technews</a></font> </li>
                    
                    <li><a href="16MM-VideoMS.pdf">Multi-Stream Multi-Class Fusion of Deep Networks for Video Classification.</a><br>ACM Multimedia (<b>ACM MM</b>), Amsterdam, the Netherlands, Oct., 2016. (Oral Paper) <br> <span class=authors><b>Zuxuan Wu</b>, Yu-Gang Jiang, Xi Wang, Hao Ye, Xiangyang Xue</span> </li>
                    
                    <li><a href="15MM-HDL.pdf">Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification.</a><br>ACM Multimedia (<b>ACM MM</b>), Brisbane, Australia, Oct., 2015. (Oral Paper) <br> <span class=authors><b>Zuxuan Wu</b>, Xi Wang, Yu-Gang Jiang, Hao Ye, Xiangyang Xue</span> <br><font color="red">Obtain 91.3% accuracy on the UCF-101 dataset.</font> </li>

                    <li><a href="icmr15-eval2stream.pdf">Evaluating Two-Stream CNN for Video Classification.</a><br>ACM International Conference on Multimedia Retrieval (<b>ICMR</b>), Shanghai, China, June, 2015 <a class=link href="model.txt">motion CNN model</a> <br> <span class=authors>Hao Ye, <b>Zuxuan Wu</b>, Rui-Wei Zhao, Xi Wang, Yu-Gang Jiang, Xiangyang Xue</span> </li>
                    
                    <li><a href="mm14-videoclassification.pdf">Exploring Inter-feature and Inter-class Relationships with Deep Neural Networks for Video Classification.</a><br>ACM Multimedia (<b>ACM MM</b>), Orlando, USA, Nov., 2014. (Oral Paper) <br> <span class=authors><b>Zuxuan Wu</b>, Yu-Gang Jiang, Jun Wang, Jian Pu, Xiangyang Xue</span> </li>
                </ul>
            </div>



            <div class=section>
                <h3>Professional Service</h3>
                <ul class=misc>

                    <li class=misc0> Area Chair:
                        <ul>
                            <li> Advances in Neural Information Processing Systems 2023-2024</li>
                            <li> IEEE Conference on Computer Vision and Pattern Recognition 2023-2024</li>
                        </ul>
                    </li>

                    <li class=misc0> Senior Program Committee:
                        <ul>
                            <li> AAAI Conference on Artificial Intelligenc 2023-2024</li>
                            <li>International Joint Conference on Artificial Intelligence 2023
                        </ul>
                    </li>
              

                </ul>
            </div>

            <div class=foot style="font-size:10px"></div>
        </div>
</body>



</html>
